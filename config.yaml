GPU: '0,1'
Test_GPU: '0'
seed: 20230524
experiment: ""
model: 'SSAN_DWAP'
dataset_name: 'CROHME'
curr_time: 3

epochs: 240
batch_size: 14
workers: 0
train_part: 1
valid_start: 70
save_start: 0

optimizer: Adadelta
lr: 1
lr_decay: cosine
step_ratio: 10
step_decay: 5
eps: 1e-6
weight_decay: 1e-4
beta: 0.9

dropout: True
dropout_ratio: 0.5
relu: True
gradient: 100
gradient_clip: True
use_label_mask: False

train_image_path: '/path_to/Train_crohme.npy'
eval_image_path: '/path_to/Test2014_crohme.npy'
alphabet_path: './data/crohme_alphabet.txt'

dataset:
  augmentation: False
  augmentation_scale:
    - 0.7
    - 1.4
  # SAM
  similar: False
  matrix_path: './data/symbol_statistic_total_single.pkl'
  # SSAN
  localization: True
  localization_finetune: False
  symbol_mask: False
  localization_finetune_path: '/path_to_npy'
  patch_rate: 0.333
  patch_size: 2
  mask_percent: 4

loss:
  name:
    - word
    - spatial
  weight:
    - 1
    - 1

densenet:
  ratio: 16
  growthRate: 24
  reduction: 0.5
  bottleneck: True
  use_dropout: True

encoder:
  input_channel: 1
  out_channel: 684

decoder:
  net: AttDecoder
  cell: 'GRU'
  input_size: 256
  hidden_size: 256

counting_decoder:
  in_channel: 684
  out_channel: 111

attention:
  attention_dim: 512
  word_conv_kernel: 1

attention_map_vis_path: 'vis/attention_map'
counting_map_vis_path: 'vis/counting_map'

whiten_type: None
max_step: 256

optimizer_save: False
finetune: False
checkpoint_dir: 'results'
checkpoint: ""
log_dir: 'logs'
